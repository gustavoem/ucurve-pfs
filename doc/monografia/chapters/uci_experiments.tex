% testar algoritmos de seleção de características com instâncias reais
% tipo de instância: aprendizado de máquina
% função de custo utilizada
%   -> usamos a MCE
%   -> hipótese u-curve não vale
%   -> adequação dos dados as função de custo MCE
% como avaliar? Validando o modelo
% o modelo usado é o de support vector machine
%   -> C-SVC
%   -> kernel linear
%   -> C = 100
% validação cruzada:
%   -> 10-fold se +100 amostras
%   -> leave-one-out caso contrário
% datasets utilizados
% resultados dos experimentos

Com o objetivo de testar os algoritmos de seleção de características
em problemas reais, decidimos aplicá-los a problemas de seleção de 
modelos de aprendizado computacional. Usamos as características 
selecionadas para definir um modelo de aprendizado e calculamos o erro
de classificação médio para este modelo, usando validação cruzada. Os
dados utilizados estão disponíveis no 
University of California Irvine (UCI) Machine Learning 
Repository~\cite{Lic13}.

\section{Seleção de características em aprendizado de máquina}
Os dados disponíveis no repositório UCI Machine Learning Repository
são dados de treinamento e teste de aprendizado de máquina 
supervisionado. Estes dados são compostos por múltiplos exemplos de 
tuplas com valores de características do conjunto $S$ e o rótulo da 
tupla observada, $Y$. Um modelo de aprendizado determina um conjunto de 
possíveis classificadores para o problema; quando usamos seleção de 
características, indicando que um conjunto $X \in \powerset(S)$ descreve
melhor os dados, estamos escolhendo como modelo de aprendizado o 
conjunto de classificadores que leva em consideração apenas as 
características de $X$.

Para que o conjunto $X$ de características selecionadas de fato 
determine um bom conjunto de classificadores, precisamos construir
o problema de seleção de características de maneira que isto aconteça.
Então, além de determinar que o conjunto de características seja $S$,
precisamos escolher a função de custo $c$ para o problema. 
Como discutido na seção~\ref{fund_concept:mce}, a função de custo
entropia condicional média (MCE) faz bem este papel. Além disso, a 
função MCE induz curvas em U, com poucas violações, nas cadeias do 
reticulado Booleano. Por conta das violações, este problema não é o
U-Curve, porém, como visto em ~\cite{Rei12}, podemos aproximar
a solução do problema original pela solução encontrada assumindo que
estamos no caso U-Curve.

A função de custo MCE que utilizamos neste trabalho, disponível no
arcabouço \toolname{featsel}~\cite{Reis+17}, assume que os valores
das características são discretos, portanto ainda é necessário 
discretizar os dados de treinamento do UCI que têm variáveis contínuas 
para fazermos a seleção de características no arcabouço.
A estratégia que utilizamos para tal tarefa é de 
discretizar os valores de características contínuas por quartis, 
mapeando seus valores para um inteiro entre 0 e 3. Existem entretanto 
outras estratégias mais elaboradas, como a de Fayyad e Irani~\cite{FI93}
que separa dados por classes minimizando a entropia média.

\section{Support Vector Machine com kernel linear}
\label{sec:real_instances:svm}
A seleção de características é apenas uma etapa da seleção de modelo
de aprendizado. Vamos então especificar mais o conjunto de possíveis
classificadores para os problemas que trataremos neste capítulo. Fazemos
isto ao decidir que o modelo de aprendizado que usaremos é o de
Support Vector Machine (SVM)~\cite{CL11}.
% TODO: citei um texto que é da biblioteca libSVM. Talvez o certo seria
% citar algum texto que explica exclusivamente support vector machine?

Mais especificamente, vamos trabalhar com classificadores SVM com kernel
linear e multi-classe. O funcionamento de um classificador SVM binário
(duas classes) é simples: dado um conjunto de dados de treinamento com 
dois rótulos possíveis, o classificador determina um hiperplano que 
separa no espaço os dados de treinamento, assim para classificar um dado, 
basta responder em qual lado do hiperplano este dado está localizado.
Se houverem $k$ classes, então podemos criar $k(k-1)$ classificadores
binários para cada par de classes e então, para rotular um dado,
utilizamos um esquema de votação em que a classe mais votada dentre 
todos os estes classificadores dá o rótulo ao ponto.

O modelo de SVM linear tem um parâmetro $C$ que determina como o 
hiperplano é posicionado no espaço de pontos de treinamento. Para 
valores pequenos de $C$ o hiperplano será posicionado dando preferência
a ter uma margem grande para pontos de treinamento corretamente 
classificados, mesmo que isto implique em pontos de treinamento mal 
classificados; para valores maiores de $C$, a preferência é dada para 
classificar corretamente os dados de treinamento, mesmo que a margem do
hiperplano seja pequena. Em nosso trabalho, utilizamos $C = 100$, pois
este parâmetro é regulador, isto é, diminui a complexidade do modelo
para se obter melhores resultados com poucas amostras; mas isto é o que
queremos fazer também com seleção de características, portanto o valor
alto de $C$ garante que a diminuição da complexidade do modelo é feita
de fato pela seleção de características.

\section{Validação de modelos}
Para fazer a validação dos modelos de aprendizado gerados, precisamos
estimar o erro médio de classificadores treinados em cada um destes
modelos. Para fazer isto é necessário separar os dados entre dados de
treinamento e dados de teste, mas como o número de amostras é geralmente
pequeno, fazemos o procedimento de classificação e estimação de erro
para várias escolhas de conjuntos de treinamento e teste; chamamos este
tipo de validação, que usa o mesmo exemplo como teste e treinamento, de
validação cruzada.

Para as instâncias em que o número de exemplos é superior a 100, 
usaremos a validação cruzada 10-\foreignword{fold}, para outras 
utilizaremos a validação \foreignword{leave-one-out}. A validação
cruzada 10-\foreignword{fold} separa as amostras em 10 grupos e usa
cada um deles para calcular o erro do classificador treinado com os 
outros nove. Na abordagem \foreignword{leave-one-out} separamos as
$n$ amostras em $n$ grupos e fazemos o mesmo procedimento.

\section{Experimentos com problemas de classificação}
Nesta seção apresentamos projetos de classificadores feitos
com seleção de características para conjuntos de dados do University of 
California Irvine (UCI) Machine Learning Repository~\cite{Lic13}. Após 
a fase de seleção de modelo, feita com seleção de características, 
fazemos a validação cruzada de modelos, como definidos na 
seção~\ref{sec:real_instances:svm}, utilizando a biblioteca 
libsvm~\cite{CL11}.

\subsection{Descrição dos conjuntos de dados}
\subsubsection{\gender{Iris}}
Este conjunto de dados é mais famoso do repositório UCI, e apresenta 
dados de plantas com flor do gênero Iris, conhecidas popularmente como 
lírio. Os dados descrevem cada planta com quatro variáveis, que são 
comprimento e largura de pétalas e sépalas, e as rotulam em três tipos:
\species{Iris setosa}, \species{Iris Versicolor} e 
\species{Iris Virginica}. Este conjunto possui 150 exemplos de 
rotulações.

\subsubsection{Promoters}
Chamamos de promotora uma sequência de nucleotídeos (A, T, C, G) do DNA 
que indica o começo de uma região da fita onde deve haver a transcrição. 
Este conjunto de dados contém 106 exemplos de sequências de DNA da 
bactéria \species{E. coli}. Cada sequência é formada por 57 variáveis,
que são nucleotídeos, e é rotulada em promotora ou não promotora.

\subsubsection{Wine}
Este conjunto de dados descreve vinhos em 13 variáveis, como porcentagem 
alcoólica, cor, intensidade de cor, entre outros. Os 178 exemplos de
vinhos são classificados entre três tipos.

\subsubsection{Zoo}
Este conjunto de dados contém exemplos de classificação de animais de
zoológico. Os animais são classificados em 7 possíveis grupos e são 
descritos em 17 variáveis que podem ser Booleanas, como presença de 
pelos, ser aquático, etc., ou inteiras, como a quantidade de pernas. 
Este conjunto possui 101 exemplos classificados.

\subsubsection{Lung Cancer}
Estes dados apresentam exemplos de classificação de tipos de câncer
de pulmão. São utilizadas 56 características para descrever um paciente,
mas nenhuma delas é especificada pelos autores deste conjunto de dados.
Existem 3 possíveis rótulos para cada paciente, e um total de 32 
exemplos.

\subsubsection{Breast Cancer}
O objetivo deste conjunto de dados é classificar amostras de biópsia
de tumores mamários. Estas amostras contém informações de 31 variáveis
e são classificadas em tumores benignos ou malignos. Este conjunto 
possui 700 exemplos de classificação de biópsia.


\subsection{Resultados}
